{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Imports\n\nimport time\n\n%matplotlib inline\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nimport category_encoders as ce","metadata":{"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"### Settings\n\nSEED = 21\nTEST_SIZE = 0.33\nEPOCHS = 10\nBATCH_SIZE = 128\n","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"### Create dataframes\n\nTEST_FEATURES_PATH = \"/kaggle/input/lish-moa/test_features.csv\"\nTRAIN_FEATURES_PATH = \"/kaggle/input/lish-moa/train_features.csv\"\nTRAIN_TARGETS_PATH = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\nTRAIN_TARGETS_NONSCORED_PATH = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\nSAMPLE_SUB_PATH = \"/kaggle/input/lish-moa/sample_submission.csv\"\n\ntest_features_df = pd.read_csv(TEST_FEATURES_PATH).sort_values(by='sig_id')\ntrain_features_df = pd.read_csv(TRAIN_FEATURES_PATH).sort_values(by='sig_id')\ntrain_targets_df = pd.read_csv(TRAIN_TARGETS_PATH).sort_values(by='sig_id')\ntrain_targets_nonscored_df = pd.read_csv(TRAIN_TARGETS_NONSCORED_PATH)\nsample_sub_df = pd.read_csv(SAMPLE_SUB_PATH).sort_values(by='sig_id')","metadata":{"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# Encode training categorical features\nenc = ce.BinaryEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(train_features_df)\ntrain_features_enc_df = enc.transform(train_features_df).drop(columns=['sig_id'])\n\n\n# Encode testing categorical features\nenc = ce.BinaryEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(test_features_df)\ntest_features_enc_df = enc.transform(test_features_df).drop(columns=['sig_id'])","metadata":{"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","output_type":"stream"}]},{"cell_type":"code","source":"### Verify\n\ntrain_features_enc_df.head()\n","metadata":{"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"   cp_type_0  cp_type_1  cp_time_0  cp_time_1  cp_time_2  cp_dose_0  \\\n0          0          1          0          0          1          0   \n1          0          1          0          1          0          0   \n2          0          1          0          1          1          0   \n3          0          1          0          1          1          0   \n4          0          1          0          1          0          1   \n\n   cp_dose_1     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n0          1  1.0620  0.5577 -0.2479  ...  0.2862  0.2584  0.8076  0.5523   \n1          1  0.0743  0.4087  0.2991  ... -0.4265  0.7543  0.4708  0.0230   \n2          1  0.6280  0.5817  1.5540  ... -0.7250 -0.6297  0.6103  0.0223   \n3          1 -0.5138 -0.2491 -0.2656  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4          0 -0.3254 -0.4009  0.9700  ...  0.0042  0.0048  0.6670  1.0690   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n0 -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n1  0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n2 -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n3 -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n\n[5 rows x 879 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp_type_0</th>\n      <th>cp_type_1</th>\n      <th>cp_time_0</th>\n      <th>cp_time_1</th>\n      <th>cp_time_2</th>\n      <th>cp_dose_0</th>\n      <th>cp_dose_1</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>...</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0620</td>\n      <td>0.5577</td>\n      <td>-0.2479</td>\n      <td>...</td>\n      <td>0.2862</td>\n      <td>0.2584</td>\n      <td>0.8076</td>\n      <td>0.5523</td>\n      <td>-0.1912</td>\n      <td>0.6584</td>\n      <td>-0.3981</td>\n      <td>0.2139</td>\n      <td>0.3801</td>\n      <td>0.4176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0743</td>\n      <td>0.4087</td>\n      <td>0.2991</td>\n      <td>...</td>\n      <td>-0.4265</td>\n      <td>0.7543</td>\n      <td>0.4708</td>\n      <td>0.0230</td>\n      <td>0.2957</td>\n      <td>0.4899</td>\n      <td>0.1522</td>\n      <td>0.1241</td>\n      <td>0.6077</td>\n      <td>0.7371</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.6280</td>\n      <td>0.5817</td>\n      <td>1.5540</td>\n      <td>...</td>\n      <td>-0.7250</td>\n      <td>-0.6297</td>\n      <td>0.6103</td>\n      <td>0.0223</td>\n      <td>-1.3240</td>\n      <td>-0.3174</td>\n      <td>-0.6417</td>\n      <td>-0.2187</td>\n      <td>-1.4080</td>\n      <td>0.6931</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.5138</td>\n      <td>-0.2491</td>\n      <td>-0.2656</td>\n      <td>...</td>\n      <td>-2.0990</td>\n      <td>-0.6441</td>\n      <td>-5.6300</td>\n      <td>-1.3780</td>\n      <td>-0.8632</td>\n      <td>-1.2880</td>\n      <td>-1.6210</td>\n      <td>-0.8784</td>\n      <td>-0.3876</td>\n      <td>-0.8154</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.3254</td>\n      <td>-0.4009</td>\n      <td>0.9700</td>\n      <td>...</td>\n      <td>0.0042</td>\n      <td>0.0048</td>\n      <td>0.6670</td>\n      <td>1.0690</td>\n      <td>0.5523</td>\n      <td>-0.3031</td>\n      <td>0.1094</td>\n      <td>0.2885</td>\n      <td>-0.3786</td>\n      <td>0.7125</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 879 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"### check how many 1's are in each class\n\nvalue_counts_arr = np.sort([train_targets_df[col].value_counts()[1] for col in train_targets_df.columns])\n\nprint(value_counts_arr)\n\nprint(pd.Series(value_counts_arr).describe())","metadata":{"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"[  1   1   1   6   6   6   6   6   6   6   6   6   6   6   6   6   6   6\n   6   7   7   7   7  12  12  12  12  12  12  12  12  12  12  12  13  13\n  17  18  18  18  18  18  18  18  18  18  18  18  18  18  19  19  19  19\n  23  23  24  24  24  24  24  25  25  25  25  25  25  25  25  26  26  26\n  29  30  30  30  30  30  30  31  31  31  31  32  35  36  36  36  36  36\n  36  36  36  36  36  36  36  37  37  37  37  37  37  38  39  42  42  42\n  42  43  44  47  48  48  48  48  48  48  48  49  50  51  54  54  54  55\n  55  56  56  59  60  60  60  61  61  61  62  62  66  67  67  68  71  72\n  72  72  73  73  73  73  73  74  74  80  80  84  85  89  89  92  93  96\n  96  96  97  98 102 103 104 106 106 115 115 119 121 127 130 151 158 165\n 170 190 192 223 236 241 264 266 267 270 273 279 281 283 297 301 316 336\n 340 360 367 402 404 424 435 726 832]\ncount    207.000000\nmean      81.376812\nstd      115.017572\nmin        1.000000\n25%       19.000000\n50%       38.000000\n75%       82.000000\nmax      832.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"### Plot histogram of 1s counts in classes \n\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\n\nplt.hist(value_counts_arr, 50, facecolor='g', alpha=0.75)\nplt.xlabel('Number of 1\\'s')\nplt.ylabel('Number of classes')\nplt.title('Value Counts of 1\\'s in classes')\nplt.show()","metadata":{"trusted":true},"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"### Split training data into train/valid\n\nx_train,x_valid,y_train,y_valid = train_test_split(train_features_enc_df,train_targets_df.drop(columns=['sig_id']),test_size=TEST_SIZE, random_state=SEED)\n\n\ntemp = 0\n\nfor col in y_train.columns:\n    if len(np.unique(y_train[col])) == 1:\n        print('Class {} only contains zeros'.format(col))\n        temp = 1\n\nif temp == 0:\n    print('No classes have all zeros!')","metadata":{"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"No classes have all zeros!\n","output_type":"stream"}]},{"cell_type":"code","source":"### Verify\nx_train.head()","metadata":{"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"       cp_type_0  cp_type_1  cp_time_0  cp_time_1  cp_time_2  cp_dose_0  \\\n16532          1          0          0          1          0          0   \n14272          0          1          0          1          0          1   \n5491           0          1          0          1          0          0   \n4567           0          1          0          1          0          1   \n4889           0          1          0          0          1          0   \n\n       cp_dose_1     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n16532          1  1.0510 -0.6319 -0.3564  ...  0.2128  0.3130  0.0629 -0.9544   \n14272          0  0.1481 -0.5605  0.3866  ...  0.2127 -1.2510  0.7155 -0.4502   \n5491           1 -1.1170 -0.6044 -0.4348  ...  0.4288  0.5469  0.2472  0.1102   \n4567           0  0.2343 -0.7714  0.1511  ... -0.6838 -0.4189 -0.4152 -0.3811   \n4889           1 -0.8858 -0.6730  0.0116  ...  1.2980  0.3778  0.6573  0.7211   \n\n         c-94    c-95    c-96    c-97    c-98    c-99  \n16532 -0.3254  0.7104  0.1161 -0.6445  0.2287 -0.2091  \n14272 -0.4695 -0.1401 -0.1135 -0.4783 -0.1852 -0.6711  \n5491  -0.0422 -0.4896 -1.1250  0.8392  0.0776 -0.3560  \n4567   0.4572  0.4923 -0.2245 -0.1298 -0.3728 -0.6815  \n4889  -0.0763  1.3730  0.1832 -0.3524  0.1080 -0.1521  \n\n[5 rows x 879 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp_type_0</th>\n      <th>cp_type_1</th>\n      <th>cp_time_0</th>\n      <th>cp_time_1</th>\n      <th>cp_time_2</th>\n      <th>cp_dose_0</th>\n      <th>cp_dose_1</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>...</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16532</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0510</td>\n      <td>-0.6319</td>\n      <td>-0.3564</td>\n      <td>...</td>\n      <td>0.2128</td>\n      <td>0.3130</td>\n      <td>0.0629</td>\n      <td>-0.9544</td>\n      <td>-0.3254</td>\n      <td>0.7104</td>\n      <td>0.1161</td>\n      <td>-0.6445</td>\n      <td>0.2287</td>\n      <td>-0.2091</td>\n    </tr>\n    <tr>\n      <th>14272</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.1481</td>\n      <td>-0.5605</td>\n      <td>0.3866</td>\n      <td>...</td>\n      <td>0.2127</td>\n      <td>-1.2510</td>\n      <td>0.7155</td>\n      <td>-0.4502</td>\n      <td>-0.4695</td>\n      <td>-0.1401</td>\n      <td>-0.1135</td>\n      <td>-0.4783</td>\n      <td>-0.1852</td>\n      <td>-0.6711</td>\n    </tr>\n    <tr>\n      <th>5491</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-1.1170</td>\n      <td>-0.6044</td>\n      <td>-0.4348</td>\n      <td>...</td>\n      <td>0.4288</td>\n      <td>0.5469</td>\n      <td>0.2472</td>\n      <td>0.1102</td>\n      <td>-0.0422</td>\n      <td>-0.4896</td>\n      <td>-1.1250</td>\n      <td>0.8392</td>\n      <td>0.0776</td>\n      <td>-0.3560</td>\n    </tr>\n    <tr>\n      <th>4567</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.2343</td>\n      <td>-0.7714</td>\n      <td>0.1511</td>\n      <td>...</td>\n      <td>-0.6838</td>\n      <td>-0.4189</td>\n      <td>-0.4152</td>\n      <td>-0.3811</td>\n      <td>0.4572</td>\n      <td>0.4923</td>\n      <td>-0.2245</td>\n      <td>-0.1298</td>\n      <td>-0.3728</td>\n      <td>-0.6815</td>\n    </tr>\n    <tr>\n      <th>4889</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.8858</td>\n      <td>-0.6730</td>\n      <td>0.0116</td>\n      <td>...</td>\n      <td>1.2980</td>\n      <td>0.3778</td>\n      <td>0.6573</td>\n      <td>0.7211</td>\n      <td>-0.0763</td>\n      <td>1.3730</td>\n      <td>0.1832</td>\n      <td>-0.3524</td>\n      <td>0.1080</td>\n      <td>-0.1521</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 879 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_tf_model():\n    model = tf.keras.Sequential([\n        L.Flatten(input_shape=(1,879)),\n        L.Dense(2000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(206, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    model.summary()\n    \n    return model","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"### Make Predictions\n\ndef get_preds(model,final=False):\n\n    if 'tensorflow' in str(type(model)):\n        if final==True:\n            preds = np.array(model.predict(test_features_enc_df).astype(\"float64\"))\n        else:\n            preds = np.array(model.predict(x_valid).astype(\"float64\"))\n    else:\n        if final==True:\n            preds = np.array(model.predict_proba(test_features_enc_df))\n        else:\n            preds = np.array(model.predict_proba(x_valid))\n        \n        preds = preds[:,:,1].T\n    \n    return preds","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"### Calculate validation score\n\ndef calc_loss(vals,preds):\n\n    score = log_loss(np.ravel(vals),np.ravel(preds)) \n\n    print('Validation log loss score: {}'.format(score))\ndef run_model(model):\n\n    ### fit the model\n    fit_model(model)\n\n    print('Getting validation predictions...')\n    \n    ### get the predictions\n    temp_val_preds = get_preds(model,final=False)\n    \n    ### calculate log loss\n    calc_loss(y_valid,temp_val_preds)\n\n    val_preds.append(temp_val_preds)\n    \n    print('Calculating final predictions...')\n\n    ### final preds\n    final_preds.append(get_preds(model,final=True))\n    \n    print('Done')","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"val_preds = []\nfinal_preds = []\n","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"run_model(model_2) ","metadata":{"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Beginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\nEpoch 1/10\n125/125 [==============================] - 13s 101ms/step - loss: 0.0161 - accuracy: 0.1307 - val_loss: 0.0159 - val_accuracy: 0.1158\nEpoch 2/10\n125/125 [==============================] - 9s 72ms/step - loss: 0.0155 - accuracy: 0.1446 - val_loss: 0.0157 - val_accuracy: 0.1485\nEpoch 3/10\n125/125 [==============================] - 9s 74ms/step - loss: 0.0151 - accuracy: 0.1562 - val_loss: 0.0157 - val_accuracy: 0.1197\nEpoch 4/10\n125/125 [==============================] - 9s 73ms/step - loss: 0.0143 - accuracy: 0.1658 - val_loss: 0.0159 - val_accuracy: 0.1187\nEpoch 5/10\n125/125 [==============================] - 9s 69ms/step - loss: 0.0138 - accuracy: 0.1791 - val_loss: 0.0156 - val_accuracy: 0.1233\nEpoch 6/10\n125/125 [==============================] - 9s 71ms/step - loss: 0.0132 - accuracy: 0.2016 - val_loss: 0.0158 - val_accuracy: 0.1279\nEpoch 7/10\n125/125 [==============================] - 9s 70ms/step - loss: 0.0126 - accuracy: 0.2151 - val_loss: 0.0160 - val_accuracy: 0.1250\nEpoch 8/10\n125/125 [==============================] - 9s 72ms/step - loss: 0.0120 - accuracy: 0.2336 - val_loss: 0.0163 - val_accuracy: 0.1210\nEpoch 9/10\n125/125 [==============================] - 9s 69ms/step - loss: 0.0111 - accuracy: 0.2607 - val_loss: 0.0164 - val_accuracy: 0.1252\nEpoch 10/10\n125/125 [==============================] - 9s 69ms/step - loss: 0.0107 - accuracy: 0.2858 - val_loss: 0.0169 - val_accuracy: 0.1256\nTotal time taken to fit model:  93.01864171028137  seconds\nGetting validation predictions...\nValidation log loss score: 0.01691804090690797\nCalculating final predictions...\nDone\n","output_type":"stream"}]},{"cell_type":"code","source":"### Ensemble validation predictions\n\nprint('Ensembling validation predictions')\nval_preds_avg = np.mean(np.array(val_preds),axis=0)\n\nprint('Ensembling final predictions')\nfinal_predictions = np.mean(np.array(final_preds),axis=0)","metadata":{"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Ensembling validation predictions\nEnsembling final predictions\n","output_type":"stream"}]},{"cell_type":"code","source":"### Calculate ensemble validaiton loss\n\nprint('Calculating ensemble validation loss...')\n\ncalc_loss(y_valid,val_preds_avg)","metadata":{"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Calculating ensemble validation loss...\nValidation log loss score: 0.01691804090690797\n","output_type":"stream"}]},{"cell_type":"code","source":"### Insight into validation predictions\n\nprint(np.min(val_preds_avg))\nprint(np.max(val_preds_avg))\nprint(pd.DataFrame(val_preds_avg).describe())","metadata":{"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"2.0812303805461224e-31\n1.0\n                0             1             2             3             4    \\\ncount  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03   \nmean   4.760536e-04  3.436901e-04  1.012242e-03  3.471435e-03  6.731886e-03   \nstd    1.116169e-03  6.692053e-04  1.161711e-03  1.207998e-02  2.038691e-02   \nmin    1.217297e-21  3.005029e-17  8.598053e-21  1.591068e-14  1.075696e-14   \n25%    4.903723e-05  3.003962e-05  2.715141e-04  1.551360e-04  1.875460e-04   \n50%    1.736879e-04  1.360476e-04  6.359816e-04  6.479621e-04  1.063555e-03   \n75%    4.797131e-04  3.822595e-04  1.325428e-03  2.445489e-03  4.762292e-03   \nmax    2.898359e-02  1.365128e-02  1.416847e-02  4.089799e-01  5.086467e-01   \n\n                5             6             7             8             9    \\\ncount  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03   \nmean   1.776980e-03  1.677838e-03  2.876456e-03  1.789901e-04  3.674132e-03   \nstd    3.153071e-03  4.287470e-03  5.742991e-03  1.145817e-03  1.895888e-02   \nmin    6.847900e-16  2.153601e-19  1.914155e-16  2.118910e-12  3.233445e-14   \n25%    2.195239e-04  1.311898e-04  2.415925e-04  1.197505e-05  7.950328e-05   \n50%    8.014739e-04  4.532039e-04  1.083314e-03  4.243252e-05  3.528595e-04   \n75%    2.079681e-03  1.467854e-03  3.198802e-03  1.328737e-04  1.536742e-03   \nmax    6.238621e-02  7.760528e-02  1.260548e-01  8.914763e-02  8.131533e-01   \n\n       ...           196           197           198           199  \\\ncount  ...  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03   \nmean   ...  1.657833e-04  1.439804e-03  1.501936e-03  1.456413e-02   \nstd    ...  1.830326e-04  5.337775e-03  2.510788e-03  1.079197e-01   \nmin    ...  3.926248e-21  1.118340e-17  1.150465e-17  1.960557e-12   \n25%    ...  4.334763e-05  6.576661e-05  2.220720e-04  1.682157e-05   \n50%    ...  1.165398e-04  2.518594e-04  6.662011e-04  7.338580e-05   \n75%    ...  2.250969e-04  8.458346e-04  1.765788e-03  3.173202e-04   \nmax    ...  2.482951e-03  1.366241e-01  4.955110e-02  9.997860e-01   \n\n                200           201           202           203           204  \\\ncount  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03  7.859000e+03   \nmean   2.671133e-03  2.430034e-04  4.281111e-03  6.376647e-04  1.365672e-03   \nstd    1.781597e-02  2.974577e-04  4.095471e-02  7.033224e-04  1.194554e-02   \nmin    2.394312e-16  2.243611e-22  2.231072e-23  8.433176e-19  8.861262e-17   \n25%    1.122655e-04  5.531185e-05  2.598810e-05  1.946837e-04  4.924189e-05   \n50%    4.022717e-04  1.561642e-04  1.092939e-04  4.385710e-04  2.488792e-04   \n75%    1.464233e-03  3.221929e-04  5.091280e-04  8.344501e-04  8.545071e-04   \nmax    7.977673e-01  3.719985e-03  9.945369e-01  9.147346e-03  7.636141e-01   \n\n                205  \ncount  7.859000e+03  \nmean   8.975849e-04  \nstd    1.508681e-03  \nmin    1.577154e-18  \n25%    1.531243e-04  \n50%    4.301965e-04  \n75%    1.008034e-03  \nmax    2.919731e-02  \n\n[8 rows x 206 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"### Output final predictions\n\nsample_sub_df.iloc[:,1:] = final_predictions\nsample_sub_df.to_csv('submission.csv',index=False)\n","metadata":{"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"### Insight into final predictions\n\nsample_sub_df.describe()","metadata":{"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"       5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\ncount                 3.982000e+03            3.982000e+03    3.982000e+03   \nmean                  5.018097e-04            3.576555e-04    1.039613e-03   \nstd                   1.051692e-03            6.384903e-04    1.213173e-03   \nmin                   3.815770e-21            9.808111e-17    2.639259e-20   \n25%                   5.739715e-05            3.524015e-05    2.702624e-04   \n50%                   2.007931e-04            1.437962e-04    6.554723e-04   \n75%                   5.233064e-04            4.201680e-04    1.353055e-03   \nmax                   1.776883e-02            1.234487e-02    1.361996e-02   \n\n       acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\ncount                    3.982000e+03                       3.982000e+03   \nmean                     3.744616e-03                       7.482985e-03   \nstd                      1.234916e-02                       2.320339e-02   \nmin                      4.360198e-14                       3.484092e-14   \n25%                      1.586676e-04                       2.260506e-04   \n50%                      6.898493e-04                       1.219481e-03   \n75%                      2.692692e-03                       5.206846e-03   \nmax                      2.496358e-01                       4.639568e-01   \n\n       acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\ncount                    3.982000e+03                3.982000e+03   \nmean                     1.818805e-03                1.842716e-03   \nstd                      3.061272e-03                4.858713e-03   \nmin                      1.318523e-15                7.498876e-19   \n25%                      2.473146e-04                1.422390e-04   \n50%                      8.457154e-04                5.243570e-04   \n75%                      2.078705e-03                1.601398e-03   \nmax                      8.142373e-02                1.360285e-01   \n\n       adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\ncount                   3.982000e+03                3.982000e+03   \nmean                    2.805617e-03                1.902148e-04   \nstd                     5.601455e-03                8.828740e-04   \nmin                     6.108938e-16                4.245354e-12   \n25%                     3.007203e-04                1.399797e-05   \n50%                     1.218379e-03                4.640054e-05   \n75%                     3.212333e-03                1.376271e-04   \nmax                     1.764491e-01                2.896479e-02   \n\n       adrenergic_receptor_agonist  ...  \\\ncount                 3.982000e+03  ...   \nmean                  4.374351e-03  ...   \nstd                   2.699795e-02  ...   \nmin                   4.197467e-14  ...   \n25%                   9.564670e-05  ...   \n50%                   4.211515e-04  ...   \n75%                   1.767769e-03  ...   \nmax                   8.380942e-01  ...   \n\n       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\ncount                           3.982000e+03  3.982000e+03     3.982000e+03   \nmean                            1.726395e-04  1.269920e-03     1.628212e-03   \nstd                             1.868005e-04  6.819199e-03     2.872513e-03   \nmin                             1.898741e-20  4.070934e-17     2.498414e-17   \n25%                             4.709908e-05  6.636701e-05     2.443567e-04   \n50%                             1.231132e-04  2.467632e-04     7.198900e-04   \n75%                             2.357587e-04  8.023307e-04     1.820639e-03   \nmax                             1.927853e-03  2.978964e-01     5.269942e-02   \n\n       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\ncount       3.982000e+03               3.982000e+03   \nmean        1.271978e-02               2.524127e-03   \nstd         1.030961e-01               1.067216e-02   \nmin         1.382525e-11               6.259822e-16   \n25%         1.746435e-05               1.101840e-04   \n50%         7.062201e-05               4.127175e-04   \n75%         2.999678e-04               1.379214e-03   \nmax         9.997497e-01               2.124372e-01   \n\n       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor     vitamin_b  \\\ncount                           3.982000e+03     3.982000e+03  3.982000e+03   \nmean                            2.456178e-04     4.071003e-03  6.645974e-04   \nstd                             2.825965e-04     3.756443e-02  7.364884e-04   \nmin                             7.452411e-22     9.716953e-23  3.861492e-18   \n25%                             5.917291e-05     2.354216e-05  2.100840e-04   \n50%                             1.672208e-04     1.097100e-04  4.780293e-04   \n75%                             3.319457e-04     5.443394e-04  8.638948e-04   \nmax                             3.217161e-03     9.919888e-01  1.029816e-02   \n\n       vitamin_d_receptor_agonist  wnt_inhibitor  \ncount                3.982000e+03   3.982000e+03  \nmean                 1.976422e-03   9.183822e-04  \nstd                  2.338818e-02   1.524512e-03  \nmin                  2.527403e-16   4.820999e-18  \n25%                  5.101303e-05   1.705512e-04  \n50%                  2.477765e-04   4.559457e-04  \n75%                  8.887947e-04   1.052059e-03  \nmax                  9.383497e-01   2.283168e-02  \n\n[8 rows x 206 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>...</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>...</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.018097e-04</td>\n      <td>3.576555e-04</td>\n      <td>1.039613e-03</td>\n      <td>3.744616e-03</td>\n      <td>7.482985e-03</td>\n      <td>1.818805e-03</td>\n      <td>1.842716e-03</td>\n      <td>2.805617e-03</td>\n      <td>1.902148e-04</td>\n      <td>4.374351e-03</td>\n      <td>...</td>\n      <td>1.726395e-04</td>\n      <td>1.269920e-03</td>\n      <td>1.628212e-03</td>\n      <td>1.271978e-02</td>\n      <td>2.524127e-03</td>\n      <td>2.456178e-04</td>\n      <td>4.071003e-03</td>\n      <td>6.645974e-04</td>\n      <td>1.976422e-03</td>\n      <td>9.183822e-04</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.051692e-03</td>\n      <td>6.384903e-04</td>\n      <td>1.213173e-03</td>\n      <td>1.234916e-02</td>\n      <td>2.320339e-02</td>\n      <td>3.061272e-03</td>\n      <td>4.858713e-03</td>\n      <td>5.601455e-03</td>\n      <td>8.828740e-04</td>\n      <td>2.699795e-02</td>\n      <td>...</td>\n      <td>1.868005e-04</td>\n      <td>6.819199e-03</td>\n      <td>2.872513e-03</td>\n      <td>1.030961e-01</td>\n      <td>1.067216e-02</td>\n      <td>2.825965e-04</td>\n      <td>3.756443e-02</td>\n      <td>7.364884e-04</td>\n      <td>2.338818e-02</td>\n      <td>1.524512e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.815770e-21</td>\n      <td>9.808111e-17</td>\n      <td>2.639259e-20</td>\n      <td>4.360198e-14</td>\n      <td>3.484092e-14</td>\n      <td>1.318523e-15</td>\n      <td>7.498876e-19</td>\n      <td>6.108938e-16</td>\n      <td>4.245354e-12</td>\n      <td>4.197467e-14</td>\n      <td>...</td>\n      <td>1.898741e-20</td>\n      <td>4.070934e-17</td>\n      <td>2.498414e-17</td>\n      <td>1.382525e-11</td>\n      <td>6.259822e-16</td>\n      <td>7.452411e-22</td>\n      <td>9.716953e-23</td>\n      <td>3.861492e-18</td>\n      <td>2.527403e-16</td>\n      <td>4.820999e-18</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.739715e-05</td>\n      <td>3.524015e-05</td>\n      <td>2.702624e-04</td>\n      <td>1.586676e-04</td>\n      <td>2.260506e-04</td>\n      <td>2.473146e-04</td>\n      <td>1.422390e-04</td>\n      <td>3.007203e-04</td>\n      <td>1.399797e-05</td>\n      <td>9.564670e-05</td>\n      <td>...</td>\n      <td>4.709908e-05</td>\n      <td>6.636701e-05</td>\n      <td>2.443567e-04</td>\n      <td>1.746435e-05</td>\n      <td>1.101840e-04</td>\n      <td>5.917291e-05</td>\n      <td>2.354216e-05</td>\n      <td>2.100840e-04</td>\n      <td>5.101303e-05</td>\n      <td>1.705512e-04</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.007931e-04</td>\n      <td>1.437962e-04</td>\n      <td>6.554723e-04</td>\n      <td>6.898493e-04</td>\n      <td>1.219481e-03</td>\n      <td>8.457154e-04</td>\n      <td>5.243570e-04</td>\n      <td>1.218379e-03</td>\n      <td>4.640054e-05</td>\n      <td>4.211515e-04</td>\n      <td>...</td>\n      <td>1.231132e-04</td>\n      <td>2.467632e-04</td>\n      <td>7.198900e-04</td>\n      <td>7.062201e-05</td>\n      <td>4.127175e-04</td>\n      <td>1.672208e-04</td>\n      <td>1.097100e-04</td>\n      <td>4.780293e-04</td>\n      <td>2.477765e-04</td>\n      <td>4.559457e-04</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.233064e-04</td>\n      <td>4.201680e-04</td>\n      <td>1.353055e-03</td>\n      <td>2.692692e-03</td>\n      <td>5.206846e-03</td>\n      <td>2.078705e-03</td>\n      <td>1.601398e-03</td>\n      <td>3.212333e-03</td>\n      <td>1.376271e-04</td>\n      <td>1.767769e-03</td>\n      <td>...</td>\n      <td>2.357587e-04</td>\n      <td>8.023307e-04</td>\n      <td>1.820639e-03</td>\n      <td>2.999678e-04</td>\n      <td>1.379214e-03</td>\n      <td>3.319457e-04</td>\n      <td>5.443394e-04</td>\n      <td>8.638948e-04</td>\n      <td>8.887947e-04</td>\n      <td>1.052059e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.776883e-02</td>\n      <td>1.234487e-02</td>\n      <td>1.361996e-02</td>\n      <td>2.496358e-01</td>\n      <td>4.639568e-01</td>\n      <td>8.142373e-02</td>\n      <td>1.360285e-01</td>\n      <td>1.764491e-01</td>\n      <td>2.896479e-02</td>\n      <td>8.380942e-01</td>\n      <td>...</td>\n      <td>1.927853e-03</td>\n      <td>2.978964e-01</td>\n      <td>5.269942e-02</td>\n      <td>9.997497e-01</td>\n      <td>2.124372e-01</td>\n      <td>3.217161e-03</td>\n      <td>9.919888e-01</td>\n      <td>1.029816e-02</td>\n      <td>9.383497e-01</td>\n      <td>2.283168e-02</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 206 columns</p>\n</div>"},"metadata":{}}]}]}